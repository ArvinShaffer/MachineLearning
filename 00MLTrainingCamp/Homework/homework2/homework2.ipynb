{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWf0vWzZiHLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f6ad9c-34f3-4ecb-8dc8-a2ba7cc65f12"
      },
      "source": [
        "!pip install lightgbm xgboost catboost category-encoders sklearn pandas==1.1.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/41/24e14322b9986cf72a8763e0a0a69cc256cf963cf9502c8f0044a62c1ae8/catboost-0.26-cp37-none-manylinux1_x86_64.whl (69.2MB)\n",
            "\u001b[K     |████████████████████████████████| 69.2MB 46kB/s \n",
            "\u001b[?25hCollecting category-encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category-encoders) (0.10.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.5) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Installing collected packages: catboost, category-encoders\n",
            "Successfully installed catboost-0.26 category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo6yKigNidFR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ds = pd.read_excel('./final/Description.xlsx')\n",
        "train_ini = pd.read_csv('./final/train_final.csv', engine='python')\n",
        "test_ini = pd.read_csv('./final/test_final.csv', engine='python')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfRLkdMuidQo"
      },
      "source": [
        "TRAIN_IDX=train_ini.shape[0]\n",
        "TEST_IDX = TRAIN_IDX + test_ini.shape[0]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhKL4eILidTa"
      },
      "source": [
        "data = pd.concat([train_ini, test_ini], axis=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeFhS_1eidWJ"
      },
      "source": [
        "#data.columns.to_list()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92WUNKuuidYt"
      },
      "source": [
        "train = data.iloc[:TRAIN_IDX, :]\n",
        "test = data.iloc[TRAIN_IDX:TEST_IDX, :]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og3y0emYidbW"
      },
      "source": [
        "import lightgbm as lgb\n",
        "train_dataset = lgb.Dataset(train.drop(columns='loan_status'), train['loan_status'])\n",
        "test_dataset = lgb.Dataset(test.drop(columns='loan_status'), test['loan_status'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFebDlmTjfA9"
      },
      "source": [
        "param = {'num_leaves': 31, 'objective': 'binary', 'metric':'binary_error'}\n",
        "num_round = 2000"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApaBrtp1jm4y"
      },
      "source": [
        "#model = lgb.train(param, train_dataset, num_boost_round=num_round, valid_sets=[train_dataset, test_dataset])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNq9EPBujs37"
      },
      "source": [
        "import io\n",
        "import multiprocessing\n",
        "from contextlib import redirect_stdout\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass, asdict\n",
        "import hyperopt.pyll\n",
        "from hyperopt import fmin, tpe, hp\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "\n",
        "import copy\n",
        "cpu_count = 4\n",
        "use_gpu = False\n",
        "@dataclass\n",
        "class LGBOpt:\n",
        "    num_threads: any = hp.choice('num_threads', [cpu_count])\n",
        "    num_leaves: any = hp.choice('num_leaves', [64])\n",
        "    metric: any = hp.choice('metric', ['binary_error'])\n",
        "    num_round: any = hp.choice('num_rounds', [1000])\n",
        "    objective: any = hp.choice('objective', ['binary'])\n",
        "    learning_rate: any = hp.uniform('learning_rate', 0.01, 0.1)\n",
        "    feature_fraction: any = hp.uniform('feature_fraction', 0.5, 1.0)\n",
        "    bagging_fraction: any = hp.uniform('bagging_fraction', 0.8, 1.0)\n",
        "    device_type: any = hp.choice('device_tpye', ['gpu']) if use_gpu else hp.choice('device_type',\n",
        "                                                                                   ['cpu'])\n",
        "    boosting: any = hp.choice('boosting', ['gbdt', 'dart', 'goss'])\n",
        "    extra_trees: any = hp.choice('extra_tress', [False, True])\n",
        "    drop_rate: any = hp.uniform('drop_rate', 0, 0.2)\n",
        "    uniform_drop: any = hp.choice('uniform_drop', [True, False])\n",
        "    lambda_l1: any = hp.uniform('lambda_l1', 0, 10)  # TODO: Check range\n",
        "    lambda_l2: any = hp.uniform('lambda_l2', 0, 10)  # TODO: Check range\n",
        "    min_gain_to_split: any = hp.uniform('min_gain_to_split', 0, 1)  # TODO: Check range\n",
        "    min_data_in_bin = hp.choice('min_data_in_bin', [3, 5, 10, 15, 20, 50])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_common_params():\n",
        "        return {'num_thread': 4, 'num_leaves': 12, 'metric': 'binary', 'objective': 'binary',\n",
        "                'num_round': 1000, 'learning_rate': 0.01, 'feature_fraction': 0.8, 'bagging_fraction': 0.8}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChrQb5dkkxxf"
      },
      "source": [
        "class FitterBase(object):\n",
        "    def __init__(self, label, metric, max_eval=100, opt=None):\n",
        "        self.label = label\n",
        "        self.metric = metric\n",
        "        self.opt_params = dict()\n",
        "        self.max_eval = max_eval\n",
        "        self.opt = opt\n",
        "\n",
        "    def get_loss(self, y, y_pred):\n",
        "        if self.metric == 'error':\n",
        "            return 1 - accuracy_score(y, y_pred)\n",
        "        elif self.metric == 'precision':\n",
        "            return 1 - precision_score(y, y_pred)\n",
        "        elif self.metric == 'recall':\n",
        "            return 1 - recall_score(y, y_pred)\n",
        "        elif self.metric == 'macro_f1':\n",
        "            return 1 - f1_score(y, y_pred, average='macro')\n",
        "        elif self.metric == 'micro_f1':\n",
        "            return 1 - f1_score(y, y_pred, average='micro')\n",
        "        elif self.metric == 'auc':  # TODO: Add a warning checking if y_predict is all [0, 1], it should be probability\n",
        "            return 1 - roc_auc_score(y, y_pred)\n",
        "        else:\n",
        "            raise Exception(\"Not implemented yet.\")\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UtWjqrbkx0q"
      },
      "source": [
        "class LGBFitter(FitterBase):\n",
        "    def __init__(self, label='label', metric='error', opt: LGBOpt = None, max_eval=100):\n",
        "        super(LGBFitter, self).__init__(label, metric, max_eval)\n",
        "        if opt is not None:\n",
        "            self.opt = opt\n",
        "        else:\n",
        "            self.opt = LGBOpt()\n",
        "        self.best_round = None\n",
        "        self.clf = None\n",
        "\n",
        "    def train(self, train_df, eval_df, params=None, use_best_eval=True):\n",
        "        self.best_round = None\n",
        "        dtrain = lgb.Dataset(train_df.drop(columns=[self.label]), train_df[self.label])\n",
        "        deval = lgb.Dataset(eval_df.drop(columns=[self.label]), eval_df[self.label])\n",
        "        evallist = [dtrain, deval]\n",
        "        if params is None:\n",
        "            use_params = deepcopy(self.opt_params)\n",
        "        else:\n",
        "            use_params = deepcopy(params)\n",
        "\n",
        "        num_round = use_params.pop('num_round')\n",
        "        if use_best_eval:\n",
        "            with io.StringIO() as buf, redirect_stdout(buf):\n",
        "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
        "                output = buf.getvalue().split(\"\\n\")\n",
        "            min_error = np.inf\n",
        "            min_index = 0\n",
        "            for idx in range(len(output) - 1):\n",
        "                if len(output[idx].split(\"\\t\")) == 3:\n",
        "                    temp = float(output[idx].split(\"\\t\")[2].split(\":\")[1])\n",
        "                    if min_error > temp:\n",
        "                        min_error = temp\n",
        "                        min_index = int(output[idx].split(\"\\t\")[0][1:-1])\n",
        "            print(\"The minimum is attained in round %d\" % (min_index + 1))\n",
        "            self.best_round = min_index + 1\n",
        "            return output\n",
        "        else:\n",
        "            with io.StringIO() as buf, redirect_stdout(buf):\n",
        "                self.clf = lgb.train(use_params, dtrain, num_round, valid_sets=evallist)\n",
        "                output = buf.getvalue().split(\"\\n\")\n",
        "            self.best_round = num_round\n",
        "            return output\n",
        "\n",
        "    def search(self, train_df, eval_df, use_best_eval=True):\n",
        "        self.opt_params = dict()\n",
        "\n",
        "        def train_impl(params):\n",
        "            self.train(train_df, eval_df, params, use_best_eval)\n",
        "            if self.metric == 'auc':\n",
        "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "            else:\n",
        "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                           num_iteration=self.best_round) > 0.5).astype(int)\n",
        "            return self.get_loss(eval_df[self.label], y_pred)\n",
        "\n",
        "        self.opt_params = fmin(train_impl, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
        "\n",
        "    def search_k_fold(self, k_fold, data, use_best_eval=True):\n",
        "        self.opt_params = dict()\n",
        "\n",
        "        def train_impl_nfold(params):\n",
        "            loss = list()\n",
        "            for train_id, eval_id in k_fold.split(data):\n",
        "                train_df = data.loc[train_id]\n",
        "                eval_df = data.loc[eval_id]\n",
        "                self.train(train_df, eval_df, params, use_best_eval)\n",
        "                if self.metric == 'auc':\n",
        "                    y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "                else:\n",
        "                    y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                               num_iteration=self.best_round) > 0.5).astype(int)\n",
        "                loss.append(self.get_loss(eval_df[self.label], y_pred))\n",
        "            return np.mean(loss)\n",
        "\n",
        "        self.opt_params = fmin(train_impl_nfold, asdict(self.opt), algo=tpe.suggest, max_evals=self.max_eval)\n",
        "\n",
        "    def train_k_fold(self, k_fold, train_data, test_data, params=None, drop_test_y=True, use_best_eval=True):\n",
        "        acc_result = list()\n",
        "        train_pred = np.empty(train_data.shape[0])\n",
        "        test_pred = np.empty(test_data.shape[0])\n",
        "        if drop_test_y:\n",
        "            dtest = test_data.drop(columns=self.label)\n",
        "        else:\n",
        "            dtest = test_data\n",
        "\n",
        "        models = list()\n",
        "        for train_id, eval_id in k_fold.split(train_data):\n",
        "            train_df = train_data.loc[train_id]\n",
        "            eval_df = train_data.loc[eval_id]\n",
        "            self.train(train_df, eval_df, params, use_best_eval)\n",
        "            models.append(copy.deepcopy(self.clf))\n",
        "            train_pred[eval_id] = self.clf.predict(eval_df.drop(columns=self.label), num_iteration=self.best_round)\n",
        "            if self.metric == 'auc':\n",
        "                y_pred = self.clf.predict(eval_df.drop(columns=[self.label]), num_iteration=self.best_round)\n",
        "            else:\n",
        "                y_pred = (self.clf.predict(eval_df.drop(columns=[self.label]),\n",
        "                                           num_iteration=self.best_round) > 0.5).astype(int)\n",
        "            acc_result.append(self.get_loss(eval_df[self.label], y_pred))\n",
        "            test_pred += self.clf.predict(dtest, num_iteration=self.best_round)\n",
        "        test_pred /= k_fold.n_splits\n",
        "        return train_pred, test_pred, acc_result, models"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4me1s0eokx3Q"
      },
      "source": [
        "fitter = LGBFitter(label='loan_status')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0t21lwRkx6B"
      },
      "source": [
        "params = {'num_thread': 4, 'num_leaves': 12, 'metric': 'binary', 'objective': 'binary',\n",
        "                'num_round': 2000, 'learning_rate': 0.02, 'feature_fraction': 0.8, 'bagging_fraction': 0.8}"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WObgD0bx8EIE",
        "outputId": "70cab627-9854-4216-8d86-543eeebec3aa"
      },
      "source": [
        "print(params)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_thread': 4, 'num_leaves': 12, 'metric': 'binary', 'objective': 'binary', 'num_round': 2000, 'learning_rate': 0.02, 'feature_fraction': 0.8, 'bagging_fraction': 0.8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ONV3uFfkx9p"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZTa0cH-kyAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e612e4e-ecc5-4496-d07b-ed8cc0bce51e"
      },
      "source": [
        "_, _, error_rate, _ = fitter.train_k_fold(kfold, train, test, params = params)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The minimum is attained in round 549\n",
            "The minimum is attained in round 415\n",
            "The minimum is attained in round 672\n",
            "The minimum is attained in round 410\n",
            "The minimum is attained in round 352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkX6crkDkyC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769b979a-1ffc-40d1-ba34-2a8134805053"
      },
      "source": [
        "import numpy as np\n",
        "print(np.mean(error_rate))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08014828988280316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1S-d0429MXY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}